{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:44:16.744143Z",
     "iopub.status.busy": "2025-06-06T18:44:16.743832Z",
     "iopub.status.idle": "2025-06-06T18:44:17.301454Z",
     "shell.execute_reply": "2025-06-06T18:44:17.300814Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:44:17.305072Z",
     "iopub.status.busy": "2025-06-06T18:44:17.304553Z",
     "iopub.status.idle": "2025-06-06T18:44:19.034046Z",
     "shell.execute_reply": "2025-06-06T18:44:19.033325Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext IPython.extensions.autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import hypyp.fnirs as fnirs\n",
    "from hypyp.wavelet import ComplexMorletWavelet, ComplexGaussianWavelet\n",
    "from hypyp.utils import Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load raw data from disk\n",
    "\n",
    "To use as example, we download the dataset \"Dataset of parent-child hyperscanning fNIRS recordings\" from https://researchdata.ntu.edu.sg/dataset.xhtml?persistentId=doi:10.21979/N9/35DNCW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:44:19.037655Z",
     "iopub.status.busy": "2025-06-06T18:44:19.037319Z",
     "iopub.status.idle": "2025-06-06T18:44:19.664905Z",
     "shell.execute_reply": "2025-06-06T18:44:19.664213Z"
    }
   },
   "outputs": [],
   "source": [
    "browser = fnirs.DataBrowser()\n",
    "dir = browser.download_demo_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag comparison for different wavelets\n",
    "\n",
    "We load a single subject file and set a single task, but starting with a lag, to create \"dyads\". We then compare the coherence for these lags, given a set of wavelet configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:44:19.668146Z",
     "iopub.status.busy": "2025-06-06T18:44:19.667944Z",
     "iopub.status.idle": "2025-06-06T18:45:11.722365Z",
     "shell.execute_reply": "2025-06-06T18:45:11.721731Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "my_file = '../data/NIRS/downloads/fathers/FCS01/parent/NIRS-2019-09-28_002.hdr'\n",
    "\n",
    "preprocessor = fnirs.MnePreprocessorRawToHaemo()\n",
    "\n",
    "subjects = []\n",
    "dyads = []\n",
    "\n",
    "subjects.append(fnirs.Subject(label='base', tasks=[Task('baseline', onset_time=0, duration=100)]))\n",
    "subjects.append(fnirs.Subject(label='1sec', tasks=[Task('baseline', onset_time=1, duration=101)]))\n",
    "subjects.append(fnirs.Subject(label='3sec', tasks=[Task('baseline', onset_time=3, duration=103)]))\n",
    "subjects.append(fnirs.Subject(label='5sec', tasks=[Task('baseline', onset_time=5, duration=105)]))\n",
    "subjects.append(fnirs.Subject(label='10sec', tasks=[Task('baseline', onset_time=10, duration=110)]))\n",
    "\n",
    "for subject in subjects:\n",
    "    subject.load_file(my_file, preprocessor)\n",
    "\n",
    "for subject_with_lag in subjects[1:]:\n",
    "    dyads.append(fnirs.Dyad(subjects[0], subject_with_lag, label=subject_with_lag.label))\n",
    "\n",
    "cohort = fnirs.Cohort(dyads)\n",
    "\n",
    "wavelets = [\n",
    "    ComplexMorletWavelet(period_range=(2, 100)),\n",
    "    ComplexGaussianWavelet(degree=1, period_range=(2, 100)),\n",
    "    ComplexGaussianWavelet(degree=2, period_range=(2, 100)),\n",
    "    ComplexGaussianWavelet(degree=3, period_range=(2, 100)),\n",
    "]\n",
    "\n",
    "for wavelet in wavelets:\n",
    "    cohort.compute_wtcs(ch_match=('S1_D1 hbo', 'S1_D2 hbo'), wavelet=wavelet)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
    "    fig.suptitle(f'wavelet name: {wavelet.wavelet_name_with_args}')\n",
    "    wavelet.plot_mother_wavelet(ax=axes.flatten()[0])\n",
    "    for i, dyad in enumerate(cohort.dyads):\n",
    "        _ = dyad.wtcs[0].plot(title=dyad.label, ax=axes.flatten()[i+2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypyp-3IxKTwjU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
