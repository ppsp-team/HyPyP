{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import fNIRS Data into HyPyP\n",
    "\n",
    "**Authors**: Ghazaleh Ranjbaran, Caitriona Douglas, Guillaume Dumas  \n",
    "**Date**: 2022-05-21\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to import fNIRS data into HyPyP. The steps include:\n",
    "\n",
    "1. **Loading required libraries** for interactive plotting, numerical processing, and EEG/fNIRS data handling.\n",
    "2. **Loading fNIRS tools** from HyPyP for reading data, creating montages, and epoching.\n",
    "3. **Setting the data paths** for SNIRF files (fNIRS format).\n",
    "4. **Loading the fNIRS data** using MNE functions wrapped by HyPyP.\n",
    "5. **Creating a compatible montage** using probe information and standard sensor definitions.\n",
    "6. **Creating Epoch objects** compatible with HyPyP for further analyses.\n",
    "7. **Plotting the data** to inspect sensor locations and time courses.\n",
    "\n",
    "For more details on the supported formats and montage creation, please refer to the [MNE fNIRS tutorial](https://mne.tools/stable/auto_tutorials/io/30_reading_fnirs_data.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic libraries loaded.\n"
     ]
    }
   ],
   "source": [
    "# Enable interactive plotting in a separate window\n",
    "%matplotlib qt\n",
    "\n",
    "# Import necessary libraries for numerical operations and data handling\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "\n",
    "print('Basic libraries loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading fNIRS Tools\n",
    "\n",
    "HyPyP provides specialized functions for fNIRS processing. Here we import functions for:\n",
    "\n",
    "- **load_fnirs**: Loading fNIRS data in various formats.\n",
    "- **make_fnirs_montage**: Creating a sensor montage compatible with MNE.\n",
    "- **fnirs_epoch**: Converting fNIRS data into MNE Epochs objects.\n",
    "- **fnirs_montage_ui**: A helper to build montage inputs interactively.\n",
    "\n",
    "No custom functions are defined here; these are imported from HyPyP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fNIRS tools loaded.\n"
     ]
    }
   ],
   "source": [
    "from hypyp.fnirs_tools import load_fnirs\n",
    "from hypyp.fnirs_tools import make_fnirs_montage\n",
    "from hypyp.fnirs_tools import fnirs_epoch\n",
    "\n",
    "print('fNIRS tools loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setting the Path\n",
    "\n",
    "Specify the file paths for the fNIRS data. In this example, the data is in SNIRF format and does not include an explicit montage file. Data can be found, for instance, at [this OSF link](https://osf.io/75fet/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data paths set:\n",
      "Participant 1: ../data/FNIRS/DCARE_02_sub1.snirf\n",
      "Participant 2: ../data/FNIRS/DCARE_02_sub2.snirf\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for the SNIRF data for two participants\n",
    "path_1 = \"../data/FNIRS/DCARE_02_sub1.snirf\"\n",
    "path_2 = \"../data/FNIRS/DCARE_02_sub2.snirf\"\n",
    "\n",
    "print('Data paths set:')\n",
    "print('Participant 1:', path_1)\n",
    "print('Participant 2:', path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Loading fNIRS Data\n",
    "\n",
    "HyPyP utilizes the MNE-Python library to load fNIRS data. Currently, four data types are supported:\n",
    "\n",
    "- **SNIRF** (.snirf)\n",
    "- **NIRx** (directory or hdr) – requires NIRStar version 15.0+ or Aurora version 2021+\n",
    "- **Hitachi** (.csv)\n",
    "- **BOXY** (.txt)\n",
    "\n",
    "More information can be found [here](https://mne.tools/stable/auto_tutorials/io/30_reading_fnirs_data.html).\n",
    "\n",
    "We load the data for both participants using the `load_fnirs` function. Note that the function returns a list of fNIRS data objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/blackstar/PPSP/02 - Dev/020 - Dev - Hypyp/Sandbox/HyPyP/tutorial/../data/FNIRS/DCARE_02_sub1.snirf\n",
      "Loading /Users/blackstar/PPSP/02 - Dev/020 - Dev - Hypyp/Sandbox/HyPyP/tutorial/../data/FNIRS/DCARE_02_sub2.snirf\n",
      "fNIRS data loaded for both participants.\n"
     ]
    }
   ],
   "source": [
    "# Load fNIRS data for two participants\n",
    "fnirs_data = load_fnirs(path_1, path_2, attr=None, preload=False, verbose=None)\n",
    "fnirs_participant_1 = fnirs_data[0]\n",
    "fnirs_participant_2 = fnirs_data[1]\n",
    "\n",
    "print('fNIRS data loaded for both participants.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Creating a Compatible Montage\n",
    "\n",
    "A montage defines the spatial configuration of sensors. MNE-Python offers built-in standard montages for some fNIRS devices (e.g., 'artinis-octamon' or 'artinis-brite23').\n",
    "\n",
    "There are several approaches to create a montage:\n",
    "\n",
    "1. **Using a vendor name**: Pass the vendor's name (e.g., `'artinis-octamon'`) via the `mne_standard` argument if compatible.\n",
    "2. **Using a custom file**: If a custom montage file is available, pass its directory to the `prob_directory` argument and set `create_montage` to `False`.\n",
    "3. **Interactive montage creation**: Use `fnirs_montage_ui()` to build montage inputs and then call `make_fnirs_montage()` with those parameters.\n",
    "\n",
    "In this example, we manually specify the montage inputs using a probe information file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can create the inputs list manually and use it in the same way as above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compatible montage created.\n"
     ]
    }
   ],
   "source": [
    "# Define source and detector labels\n",
    "source_labels = ['S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8']\n",
    "detector_labels = ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8']\n",
    "\n",
    "# Path to the probe information file\n",
    "prob_mat_file = '../data/FNIRS/MCARE_01_probeInfo.mat'\n",
    "\n",
    "# 3D coordinates (in mm) of anatomical landmarks\n",
    "Nz_coord = [12.62, 17.33, 16.74]    # Tip of the nose\n",
    "RPA = [21.0121020904262, 15.9632489747085, 17.2796094659563]    # Right preauricular\n",
    "LPA = [4.55522116441745, 14.6744377188919, 18.3544292678269]     # Left preauricular\n",
    "\n",
    "# Head size in mm\n",
    "head_size = 0.16\n",
    "\n",
    "# Create the montage using the provided probe information\n",
    "location = make_fnirs_montage(source_labels, detector_labels, prob_mat_file,\n",
    "                              Nz_coord, RPA, LPA, head_size)\n",
    "\n",
    "print('Compatible montage created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Creating Epoch Objects\n",
    "\n",
    "HyPyP is compatible with MNE Epochs. In this step, we convert the loaded fNIRS data into Epoch objects. The parameters `tmin`, `tmax`, and `baseline` are set according to the specifics of the fNIRS recording. Adjust these values as needed; refer to the [MNE Epochs documentation](https://mne.tools/stable/generated/mne.Epochs.html) for more details.\n",
    "\n",
    "The function `fnirs_epoch` returns a list of epoch objects – one per participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('1'), np.str_('2'), np.str_('3'), np.str_('4'), np.str_('5')]\n",
      "Multiple event values for single event times found. Creating new event value to reflect simultaneous events.\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Setting baseline interval to [-0.128, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 10 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: [np.str_('1'), np.str_('2'), np.str_('3'), np.str_('4'), np.str_('5')]\n",
      "Multiple event values for single event times found. Creating new event value to reflect simultaneous events.\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Setting baseline interval to [-0.128, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 10 original time points ...\n",
      "0 bad epochs dropped\n",
      "Epoch objects created for both participants.\n"
     ]
    }
   ],
   "source": [
    "# Create Epoch objects for both participants\n",
    "fnirs_epochs = fnirs_epoch(fnirs_participant_1, fnirs_participant_2,\n",
    "                           tmin=-0.1, tmax=1, baseline=(None, 0),\n",
    "                           preload=True, event_repeated='merge')\n",
    "\n",
    "fnirs_epo1 = fnirs_epochs[0]\n",
    "fnirs_epo2 = fnirs_epochs[1]\n",
    "\n",
    "print('Epoch objects created for both participants.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fnirs_epo1 and fnirs_epo2 are now compatible with tools provided by HyPyP (for visualization and statictical analyses check [this](https://github.com/ppsp-team/HyPyP/blob/master/tutorial/getting_started.ipynb) tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Plotting the Data\n",
    "\n",
    "Finally, we apply the montage to the epoch objects and plot the sensor configuration and time series. This allows for a visual inspection of the sensor layout and the recorded signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montage applied to both participants.\n"
     ]
    }
   ],
   "source": [
    "# Set the montage for both epoch objects\n",
    "fnirs_epo1.set_montage(location)\n",
    "fnirs_epo2.set_montage(location)\n",
    "\n",
    "print('Montage applied to both participants.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor plots displayed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 14:45:14.925 python[56804:1014910] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-02-25 14:45:14.925 python[56804:1014910] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "# Plot sensor locations with channel names for participant 1\n",
    "fnirs_epo1.plot_sensors(show_names=True)\n",
    "\n",
    "# Plot sensor locations with channel names for participant 2\n",
    "fnirs_epo2.plot_sensors(show_names=True)\n",
    "\n",
    "print('Sensor plots displayed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib as 2D backend.\n",
      "fNIRS data plots displayed.\n",
      "Dropped 0 epochs: \n",
      "The following epochs were marked as bad and are dropped:\n",
      "[]\n",
      "Channels marked as bad:\n",
      "none\n",
      "Dropped 0 epochs: \n",
      "The following epochs were marked as bad and are dropped:\n",
      "[]\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "# Plot the fNIRS data for participant 1\n",
    "fnirs_epo1.plot()\n",
    "\n",
    "# Plot the fNIRS data for participant 2\n",
    "fnirs_epo2.plot()\n",
    "\n",
    "print('fNIRS data plots displayed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c11202d2846b22eec7deaf37ea813ba92a5f75b5344a4d16688175855af7948e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
