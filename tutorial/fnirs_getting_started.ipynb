{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fNIRS Hyperscanning cohort preparation for analysis\n",
    "\n",
    "Author: Patrice Fortin\n",
    "\n",
    "Date: 2025-01-06\n",
    "\n",
    "The following Jupyter Notebook shows how to go from raw fNIRS hyperscanning recordings to produce an output file suitable for statistical analysis of Inter-Brain Synchrony (IBS).\n",
    "\n",
    "The output file can be of `.csv` or `.feather`. \n",
    "\n",
    "For an analysis example in `R` language, see `tutorial/fnirs_cohort_example.R`.\n",
    "\n",
    "For an in-depth exploration of wavelet transforms, see `tutorial/fnirs_wavelet_exploration.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:27.733276Z",
     "iopub.status.busy": "2025-06-06T18:42:27.733001Z",
     "iopub.status.idle": "2025-06-06T18:42:28.256513Z",
     "shell.execute_reply": "2025-06-06T18:42:28.255510Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:28.258801Z",
     "iopub.status.busy": "2025-06-06T18:42:28.258511Z",
     "iopub.status.idle": "2025-06-06T18:42:29.898969Z",
     "shell.execute_reply": "2025-06-06T18:42:29.898133Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext IPython.extensions.autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import hypyp.fnirs as fnirs\n",
    "from hypyp.wavelet import ComplexMorletWavelet\n",
    "from hypyp.utils import Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load raw data from disk\n",
    "\n",
    "To use as example, we download the dataset \"Dataset of parent-child hyperscanning fNIRS recordings\" from https://researchdata.ntu.edu.sg/dataset.xhtml?persistentId=doi:10.21979/N9/35DNCW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:29.901473Z",
     "iopub.status.busy": "2025-06-06T18:42:29.901100Z",
     "iopub.status.idle": "2025-06-06T18:42:30.523531Z",
     "shell.execute_reply": "2025-06-06T18:42:30.522715Z"
    }
   },
   "outputs": [],
   "source": [
    "browser = fnirs.DataBrowser()\n",
    "dir = browser.download_demo_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dyads paths (parent+child) for file loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:30.525816Z",
     "iopub.status.busy": "2025-06-06T18:42:30.525597Z",
     "iopub.status.idle": "2025-06-06T18:42:30.587778Z",
     "shell.execute_reply": "2025-06-06T18:42:30.587067Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the paths for dyads\n",
    "\n",
    "paths = [path for path in browser.list_all_files() if 'fathers' in path]\n",
    "\n",
    "dyad_paths = dict()\n",
    "\n",
    "for path in paths:\n",
    "    matches = re.search(r'(FCS\\d\\d)', path)\n",
    "    key = matches[1]\n",
    "    if not key in dyad_paths.keys():\n",
    "        dyad_paths[key] = dict()\n",
    "    \n",
    "    if 'parent' in path:\n",
    "        dyad_paths[key]['parent'] = path\n",
    "\n",
    "    if 'child' in path:\n",
    "        dyad_paths[key]['child'] = path\n",
    "\n",
    "print(dyad_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regions of Interest\n",
    "\n",
    "Let's define some region of interest. These are arbitrary for our example, for demonstration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:30.630392Z",
     "iopub.status.busy": "2025-06-06T18:42:30.630127Z",
     "iopub.status.idle": "2025-06-06T18:42:30.655654Z",
     "shell.execute_reply": "2025-06-06T18:42:30.655046Z"
    }
   },
   "outputs": [],
   "source": [
    "# dummy values\n",
    "channel_roi = fnirs.ChannelROI(OrderedDict({\n",
    "    'DPFC_L': [ 'S1_D1 hbo', 'S1_D2 hbo' ],\n",
    "    'DPFC_R': [ 'S2_D1 hbo', 'S2_D3 hbo' ],\n",
    "    'FrTemp_L': [ 'S3_D2 hbo', 'S3_D3 hbo', 'S3_D4 hbo' ],\n",
    "    'FrTemp_R': [ 'S4_D2 hbo', 'S4_D4 hbo', 'S4_D5 hbo' ],\n",
    "    'PreFr_L': [ 'S5_D3 hbo', 'S5_D4 hbo', 'S5_D6 hbo' ],\n",
    "    'PreFr_R': [ 'S6_D4 hbo', 'S6_D5 hbo', 'S6_D6 hbo' ],\n",
    "    'Temp_L': [ 'S7_D5 hbo', 'S7_D7 hbo' ],\n",
    "    'Temp_R': [ 'S8_D6 hbo', 'S8_D7 hbo' ],\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One dyad example\n",
    "\n",
    "As a simple example, let's look at a single inter-subject coherence.\n",
    "\n",
    "Let's define some task for demonstration of how we can use time based tasks.\n",
    "\n",
    "Take a look at `fnirs.Subject` constructor if you have event based tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:30.657968Z",
     "iopub.status.busy": "2025-06-06T18:42:30.657743Z",
     "iopub.status.idle": "2025-06-06T18:42:34.198254Z",
     "shell.execute_reply": "2025-06-06T18:42:34.197658Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get connectivity matrix intra-subject for validation\n",
    "\n",
    "dyad_info = list(dyad_paths.values())[0]\n",
    "parent_path = dyad_info['parent']\n",
    "child_path = dyad_info['child']\n",
    "tasks = [Task('baseline', onset_time=0, duration=60)]\n",
    "\n",
    "# Example if you have tasks from events in the recordings\n",
    "#tasks = [\n",
    "#    Task('baseline', onset_event_id=1, offset_event_id=9),\n",
    "#    Task('task1',    onset_event_id=2, offset_event_id=9),\n",
    "#    Task('task2',    onset_event_id=3, offset_event_id=9),\n",
    "#    Task('task3',    onset_event_id=4, offset_event_id=9),\n",
    "#]\n",
    "\n",
    "# use a preprocessor to clean the raw data\n",
    "# if you already have cleaned data, use fnirs.MnePreprocessorUpstream()\n",
    "preprocessor = fnirs.MnePreprocessorRawToHaemo()\n",
    "\n",
    "s1 = fnirs.Subject(label='Parent1', tasks=tasks, channel_roi=channel_roi).load_file(parent_path, preprocessor)\n",
    "s2 = fnirs.Subject(label='Child1', tasks=tasks, channel_roi=channel_roi).load_file(child_path, preprocessor)\n",
    "\n",
    "dyad = fnirs.Dyad(s1, s2)\n",
    "dyad.compute_wtcs(\n",
    "    ch_match='hbo',     # which channels to match\n",
    "    bin_seconds=15,     # split in bins of 15 seconds\n",
    "    period_cuts=[5],    # split higher and lower frequencies for comparison\n",
    ")\n",
    "\n",
    "dyad.df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:34.200255Z",
     "iopub.status.busy": "2025-06-06T18:42:34.200030Z",
     "iopub.status.idle": "2025-06-06T18:42:35.454637Z",
     "shell.execute_reply": "2025-06-06T18:42:35.453609Z"
    }
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "table = tabulate(\n",
    "    dyad.df[['dyad','subject1','subject2','roi1','roi2','channel1','channel2','task','epoch','section','bin','coherence']], \n",
    "    headers=\"keys\",\n",
    "    tablefmt='pipe'\n",
    ")\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first computed Wavelet Transform Coherence, for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:35.466947Z",
     "iopub.status.busy": "2025-06-06T18:42:35.466527Z",
     "iopub.status.idle": "2025-06-06T18:42:36.793076Z",
     "shell.execute_reply": "2025-06-06T18:42:36.792415Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = dyad.wtcs[0].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:36.795877Z",
     "iopub.status.busy": "2025-06-06T18:42:36.795576Z",
     "iopub.status.idle": "2025-06-06T18:42:38.745175Z",
     "shell.execute_reply": "2025-06-06T18:42:38.744230Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = dyad.plot_coherence_matrix_per_channel().axes[0].set_title('Dyad coherence per channel')\n",
    "_ = dyad.plot_coherence_matrix_per_roi().axes[0].set_title('Dyad coherence per region')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Coherence processing\n",
    "\n",
    "We now apply the same strategy on a cohort of dyads. We define a baseline task and a sample task.\n",
    "\n",
    "The resulting is a `Cohort` object, which encapsulates all the logic of processing, computing WTC and preparing pandas dataframe for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:38.747596Z",
     "iopub.status.busy": "2025-06-06T18:42:38.747373Z",
     "iopub.status.idle": "2025-06-06T18:42:43.453147Z",
     "shell.execute_reply": "2025-06-06T18:42:43.452253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instanciate subjects and dyads objects\n",
    "\n",
    "preprocessor = fnirs.MnePreprocessorRawToHaemo()\n",
    "tasks = [\n",
    "    Task('baseline', onset_time=0, duration=60),\n",
    "    Task('task_foo', onset_time=60, duration=60),\n",
    "]\n",
    "\n",
    "n_dyads = 10\n",
    "all_dyads = []\n",
    "\n",
    "# truncate for this example\n",
    "dyad_paths_keys = list(dyad_paths.keys())[:n_dyads]\n",
    "\n",
    "for dyad_key in dyad_paths_keys:\n",
    "    parent = fnirs.Subject(label=f'Parent {dyad_key}', tasks=tasks, channel_roi=channel_roi)\n",
    "    parent.load_file(dyad_paths[dyad_key]['parent'], preprocessor)\n",
    "\n",
    "    child = fnirs.Subject(label=f'Child {dyad_key}', tasks=tasks, channel_roi=channel_roi)\n",
    "    child.load_file(dyad_paths[dyad_key]['child'], preprocessor)\n",
    "\n",
    "    dyad = fnirs.Dyad(parent, child, label=dyad_key)\n",
    "\n",
    "    all_dyads.append(dyad)\n",
    "\n",
    "cohort = fnirs.Cohort(all_dyads)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet object\n",
    "\n",
    "Let's define our wavelet object. The following code simple instanciates the default wavelet. We do it explicitely for the sake of demonstration only.\n",
    "\n",
    "The Wavelet uses caching to avoid recomputing continuous wavelet transforms all the time for the same channels.\n",
    "\n",
    "Since the cache dictionary is shared by all dyads, a new pair with pre-computed CWT for channels will be much faster.\n",
    "\n",
    "The cache is simply a python dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:43.455974Z",
     "iopub.status.busy": "2025-06-06T18:42:43.455745Z",
     "iopub.status.idle": "2025-06-06T18:42:43.481401Z",
     "shell.execute_reply": "2025-06-06T18:42:43.480833Z"
    }
   },
   "outputs": [],
   "source": [
    "cache = dict()\n",
    "wavelet = ComplexMorletWavelet(cache=cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:42:43.483451Z",
     "iopub.status.busy": "2025-06-06T18:42:43.483244Z",
     "iopub.status.idle": "2025-06-06T18:43:56.650632Z",
     "shell.execute_reply": "2025-06-06T18:43:56.649994Z"
    }
   },
   "outputs": [],
   "source": [
    "cohort.compute_wtcs(\n",
    "    ch_match='hbo',\n",
    "    wavelet=wavelet,\n",
    "    with_intra=True, # compute intra subject for nicer display in quadrants\n",
    "    bin_seconds=10,  # split in 10 seconds bins weight balancing. See `fnirs_wavelet_exploration.ipynb` for more details\n",
    "    period_cuts=[5,10], # split frequencies in lower/higher to visualize which range has a higher coherence\n",
    "    downsample=100,  # downsamples the wtc results for saving memory and allows faster display in plots\n",
    "    verbose=False,   # use this flag to see the progress of processing\n",
    "    # If memory usage gets too big during the processing, consider dropping the WTCs and store only the mean coherence\n",
    "    #keep_wtcs=False, # delete computed WTCs after run, to avoid storing huge files\n",
    ")\n",
    "\n",
    "_ = cohort.dyads[0].wtcs[0].plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence matrix\n",
    "\n",
    "Visualize the coherence matrix for one dyad. Top left and bottom right are intra-subject coherence. Bottom left and top right are mirrors of the inter-subject coherence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:43:56.652735Z",
     "iopub.status.busy": "2025-06-06T18:43:56.652527Z",
     "iopub.status.idle": "2025-06-06T18:43:58.712125Z",
     "shell.execute_reply": "2025-06-06T18:43:58.711414Z"
    }
   },
   "outputs": [],
   "source": [
    "dyad = cohort.dyads[0]\n",
    "_ = dyad.plot_coherence_matrix_per_channel()\n",
    "_ = dyad.plot_coherence_matrix_per_roi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:43:58.714096Z",
     "iopub.status.busy": "2025-06-06T18:43:58.713919Z",
     "iopub.status.idle": "2025-06-06T18:44:01.068784Z",
     "shell.execute_reply": "2025-06-06T18:44:01.068025Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = cohort.plot_coherence_matrix_per_channel(s1_label='Parent', s2_label='Child')\n",
    "_ = cohort.plot_coherence_matrix_per_roi(s1_label='Parent', s2_label='Child')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cohort object now has a pandas dataframe object that can be used or stored for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:44:01.071088Z",
     "iopub.status.busy": "2025-06-06T18:44:01.070872Z",
     "iopub.status.idle": "2025-06-06T18:44:01.223484Z",
     "shell.execute_reply": "2025-06-06T18:44:01.222773Z"
    }
   },
   "outputs": [],
   "source": [
    "df = cohort.df[cohort.df['is_intra'] == False]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:44:01.225686Z",
     "iopub.status.busy": "2025-06-06T18:44:01.225444Z",
     "iopub.status.idle": "2025-06-06T18:44:02.069276Z",
     "shell.execute_reply": "2025-06-06T18:44:02.068445Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10), subplot_kw={'projection': 'polar'})\n",
    "_ = cohort.plot_coherence_connectogram(s1_label='Parent', s2_label='Child', ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to disk\n",
    "\n",
    "Multiple formats can be used to save the results to disk. \n",
    "\n",
    "| Format | Use case |\n",
    "| - | - |\n",
    "| `.csv` | Typical CSV file with a header, for sharing and importing in another python script or an external analysis software |\n",
    "| `.feather` | Typical pandas dataframe storage format, for further analysis |\n",
    "| `.pickle` | Used to reload the `Cohort` object for visualisation in a dashboard. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:44:02.071531Z",
     "iopub.status.busy": "2025-06-06T18:44:02.071119Z",
     "iopub.status.idle": "2025-06-06T18:44:04.600041Z",
     "shell.execute_reply": "2025-06-06T18:44:04.599421Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_file_path = '../data/results/fnirs_cohort_example.csv'\n",
    "cohort.save_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:44:04.602672Z",
     "iopub.status.busy": "2025-06-06T18:44:04.602374Z",
     "iopub.status.idle": "2025-06-06T18:44:04.919095Z",
     "shell.execute_reply": "2025-06-06T18:44:04.918473Z"
    }
   },
   "outputs": [],
   "source": [
    "feather_file_path = '../data/results/fnirs_cohort_example.feather'\n",
    "cohort.save_feather(feather_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T18:44:04.921242Z",
     "iopub.status.busy": "2025-06-06T18:44:04.921018Z",
     "iopub.status.idle": "2025-06-06T18:44:11.383622Z",
     "shell.execute_reply": "2025-06-06T18:44:11.382971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "\n",
    "results_file_path = '../data/results/fnirs_cohort_example.pickle'\n",
    "cohort.save_pickle(results_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypyp-3IxKTwjU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
